---
description: This rule applies to add a new MCP tool functions
globs: 
alwaysApply: false
---
# Adding Tools to the MCP Server

## Setting Up New API Endpoints

If your new tool needs to access an API endpoint that is different from the existing Blockscout (dynamically resolved via `get_blockscout_base_url`), BENS (`bens_url`), or Chainscout (`chainscout_url`) endpoints, follow these steps first:

1. **Add endpoint configuration to `blockscout_mcp_server/config.py`**:

   ```python
   class ServerConfig(BaseSettings):
       # Existing endpoints (examples)
       bs_api_key: str = ""
       bs_timeout: float = 120.0
       bens_url: str = "https://bens.services.blockscout.com"
       bens_timeout: float = 30.0
       chainscout_url: str = "https://chains.blockscout.com"
       chainscout_timeout: float = 15.0
       metadata_url: str = "https://metadata.services.blockscout.com"
       metadata_timeout: float = 30.0
       chain_cache_ttl_seconds: int = 1800
       
       # Add your new endpoint
       new_api_url: str = "https://api.example.com"
       new_api_timeout: float = 60.0
       # Add API key if needed
       new_api_key: str = ""
   ```

2. **Create a request helper function in `blockscout_mcp_server/tools/common.py`**:

   ```python
   async def make_new_api_request(api_path: str, params: dict | None = None) -> dict:
       """
       Make a GET request to the New API.
       
       Args:
           api_path: The API path to request
           params: Optional query parameters
           
       Returns:
           The JSON response as a dictionary
           
       Raises:
           httpx.HTTPStatusError: If the HTTP request returns an error status code
           httpx.TimeoutException: If the request times out
       """
       async with httpx.AsyncClient(timeout=config.new_api_timeout) as client:
           if params is None:
               params = {}
           if config.new_api_key:
               params["apikey"] = config.new_api_key  # Adjust based on API requirements

           url = f"{config.new_api_url}{api_path}"
           response = await client.get(url, params=params)
           response.raise_for_status()
           return response.json()
   ```

3. **Update environment configuration files**:
   - Add to `.env.example`:

     ```shell
     BLOCKSCOUT_NEW_API_URL="https://api.example.com"
     BLOCKSCOUT_NEW_API_KEY=""
     BLOCKSCOUT_NEW_API_TIMEOUT=60.0
     ```

   - Add to `Dockerfile`:

     ```dockerfile
     # Existing environment variables
     ENV BLOCKSCOUT_BS_TIMEOUT="120.0"
     ENV BLOCKSCOUT_BENS_URL="https://bens.services.blockscout.com"
     ENV BLOCKSCOUT_METADATA_URL="https://metadata.services.blockscout.com"
     ENV BLOCKSCOUT_METADATA_TIMEOUT="30.0"
     
     # New environment variables
     ENV BLOCKSCOUT_NEW_API_URL="https://api.example.com"
     ENV BLOCKSCOUT_NEW_API_KEY=""
     ENV BLOCKSCOUT_NEW_API_TIMEOUT="60.0"
     ```

## Required File Modifications

When adding a new tool to the MCP server, you need to modify these files:

1. **Create or modify a tool module file** in `blockscout_mcp_server/tools/`:
   - Choose an existing module (e.g., `block_tools.py`, `address_tools.py`) if your tool fits with existing functionality
   - Create a new module if your tool introduces a new category of functionality

2. **Register the tool in `blockscout_mcp_server/server.py`**:
   - Import the tool function
   - Register it with the MCP server using the `@mcp.tool()` decorator

3. **Update documentation in `AGENTS.md`**:
   - If you created a new module, add it to the project structure file listing
   - Add it both in the directory tree structure AND in the "Individual Tool Modules" examples section
   - If you added a tool to an existing module, update the "Examples" section to include your new tool function

## Tool Function Structure

For tools that query Blockscout API (which now support dynamic chain resolution):

```python
from typing import Annotated, Optional
from pydantic import Field
from blockscout_mcp_server.tools.common import make_blockscout_request, get_blockscout_base_url

async def tool_name(
    chain_id: Annotated[str, Field(description="The ID of the blockchain")],
    required_arg: Annotated[str, Field(description="Description of required argument")],
    optional_arg: Annotated[Optional[str], Field(description="Description of optional argument")] = None
) -> dict | list[dict] | str:  # Return type depends on response format
    """
    Descriptive docstring explaining what the tool does.
    Include use cases and examples if helpful.
    """
    # Construct API path, often with argument interpolation
    api_path = f"/api/v2/some_endpoint/{required_arg}"
    
    # Build query parameters for arguments with position: query
    query_params = {}
    if optional_arg:
        query_params["optional_param"] = optional_arg
    
    # Get the Blockscout base URL for the specified chain
    base_url = await get_blockscout_base_url(chain_id)
    
    # Make API request with the dynamic base URL
    # For multiple data sources, consider Performance Optimization patterns (concurrent API calls)
    response_data = await make_blockscout_request(base_url=base_url, api_path=api_path, params=query_params)
    
    # Process response based on implementation patterns below
    # (See Response Handling and Progress Reporting patterns)
    
    return processed_result
```

For tools that use fixed API endpoints (like BENS or other services):

```python
from typing import Annotated, Optional
from pydantic import Field
from blockscout_mcp_server.tools.common import make_bens_request  # or other API helper

async def tool_name(
    required_arg: Annotated[str, Field(description="Description of required argument")],
    optional_arg: Annotated[Optional[str], Field(description="Description of optional argument")] = None
) -> dict | list[dict] | str:  # Return type depends on response format
    """
    Descriptive docstring explaining what the tool does.
    Include use cases and examples if helpful.
    """
    # Construct API path, often with argument interpolation
    api_path = f"/api/v1/some_endpoint/{required_arg}"
    
    # Build query parameters for arguments with position: query
    query_params = {}
    if optional_arg:
        query_params["optional_param"] = optional_arg
    
    # Make API request  
    # For multiple data sources, consider Performance Optimization patterns (concurrent API calls)
    response_data = await make_bens_request(api_path=api_path, params=query_params)
    
    # Process response based on implementation patterns below
    # (See Response Handling and Progress Reporting patterns)
    
    return processed_result
```

## Implementation Patterns

### Response Handling

Choose one of these approaches based on the complexity of your response formatting needs:

#### 1. Return Full JSON Response (`return_type: dict`)

Use to return entire response:

```python
return response_data  # Simply return the full JSON response
```

#### 2. Extract Specific Fields (`return_type: dict`)

Use for simple field extraction:

```python
return {
    "field1": response_data.get("field1"),
    "field2": response_data.get("nested", {}).get("field2")
}
```

#### 3. Process JSON Arrays (`return_type: list[dict]`)

Use when iterating through items and formatting each one:

```python
items = response_data.get("items", [])
formatted_items = []
for item in items:
    formatted_items.append({
        "id": item.get("id"),
        "name": item.get("name"),
        # Other fields to extract
    })
return formatted_items
```

#### 4. Complex String Formatting (`return_type: str`)

Use for responses requiring significant text formatting, conditionals, or loops:

```python
# Example: Building a complex string with JSON formatting and pagination hints
items_data = response_data.get("items", [])
output_parts = ["["]  # Start JSON array
for i, item in enumerate(items_data):
    item_dict = {
        "field1": item.get("field1", ""),
        "field2": item.get("field2", ""),
    }
    item_str = json.dumps(item_dict)
    output_parts.append(item_str)
    if i < len(items_data) - 1:
        output_parts.append(",")
output_parts.append("]")  # End JSON array

# Add pagination hints if available
next_page_params = response_data.get("next_page_params")
if next_page_params:
    # Use the centralized helper to create an opaque cursor
    from .common import encode_cursor
    next_cursor = encode_cursor(next_page_params)
    pagination_hint = f"""

----
To get the next page call tool_name(chain_id="{chain_id}", <other_args>, cursor="{next_cursor}")"""
    output_parts.append(pagination_hint)

return "".join(output_parts)
```

#### 5. Prefixed/Suffixed Content (`return_type: str`)

Use when adding explanatory text to JSON output:

```python
import json
content = json.dumps(response_data)  # Compact JSON
prefix = """
# Explanatory Title
This is some explanatory text that helps the user understand the data.
"""
return f"{prefix}\n{content}"
```

**Note:** We use compact JSON (without indentation) to minimize the data payload size. The output is consumed by machines, not humans, so readability of the raw JSON string is not a priority.

#### 6. Handling Pagination with Opaque Cursors (`return_type: str` or `list[dict]`)

For tools that return paginated data, do not expose individual pagination parameters (like `page`, `offset`, `items_count`) in the tool's signature. Instead, use a single, opaque `cursor` string. This improves robustness and saves LLM context. The implementation involves both handling an incoming cursor and generating the next one.

**A. Handling the Incoming Cursor:**
Your tool should accept an optional `cursor` argument. If it's provided, use the `decode_cursor` helper to parse it and apply the parameters to your API call.

**B. Generating the Outgoing Cursor:**
In your response, check for `next_page_params` from the API. If they exist, use the `encode_cursor` helper to create the next cursor and include it in a user-friendly hint.

**Complete Example Pattern:**

```python
from typing import Annotated, Optional
from pydantic import Field
from blockscout_mcp_server.tools.common import make_blockscout_request, get_blockscout_base_url, encode_cursor, decode_cursor, InvalidCursorError

async def paginated_tool_name(
    chain_id: Annotated[str, Field(description="The ID of the blockchain")],
    address: Annotated[str, Field(description="The address to query")],
    cursor: Annotated[Optional[str], Field(description="The pagination cursor from a previous response to get the next page of results.")] = None,
    ctx: Context = None
) -> str:
    """
    A tool that demonstrates the correct way to handle pagination.
    """
    api_path = f"/api/v2/some_paginated_endpoint/{address}"
    query_params = {}

    # 1. Handle incoming cursor
    if cursor:
        try:
            decoded_params = decode_cursor(cursor)
            query_params.update(decoded_params)
        except InvalidCursorError:
            return "Error: Invalid or expired pagination cursor. Please make a new request without the cursor to start over."

    base_url = await get_blockscout_base_url(chain_id)
    response_data = await make_blockscout_request(base_url=base_url, api_path=api_path, params=query_params)

    output_string = process_items(response_data.get("items", []))

    # 2. Generate outgoing cursor
    next_page_params = response_data.get("next_page_params")
    if next_page_params:
        next_cursor = encode_cursor(next_page_params)
        pagination_hint = f"""

----
To get the next page call paginated_tool_name(chain_id="{chain_id}", address="{address}", cursor="{next_cursor}")"""
        output_string += pagination_hint

    return output_string
```

#### 7. Simplifying Address Objects to Save Context (`return_type: dict` or `list[dict]`)

**Rationale:** Many Blockscout API endpoints return addresses as complex JSON objects containing the hash, name, tags, etc. To conserve LLM context and encourage compositional tool use, we must simplify these objects into a single address string. If the AI needs more details about an address, it should be guided to use the dedicated `get_address_info` tool.

**Example: Transforming a Transaction Response**

**Before (Raw API Response):**
This is the verbose data we get from the Blockscout API.

```json
{
  "from": {
    "hash": "0xAbC123...",
    "name": "SenderContract",
    "is_contract": true
  },
  "to": {
    "hash": "0xDeF456...",
    "name": "ReceiverContract",
    "is_contract": true
  },
  "value": "1000000000000000000"
}
```

**After (Optimized Tool Output):**
This is the clean, concise data our tool should return.

```json
{
  "from": "0xAbC123...",
  "to": "0xDeF456...",
  "value": "1000000000000000000"
}
```

**Implementation Pattern:**
Here is how you would implement this transformation inside a tool function.

```python
async def some_tool_that_returns_addresses(chain_id: str, ...) -> dict:
    # 1. Get the raw response from the API helper
    raw_response = await make_blockscout_request(...)

    # 2. Create a copy to modify
    transformed_response = raw_response.copy()

    # 3. Simplify the 'from' address object into a string
    if isinstance(transformed_response.get("from"), dict):
        transformed_response["from"] = transformed_response["from"].get("hash")

    # 4. Simplify the 'to' address object into a string
    if isinstance(transformed_response.get("to"), dict):
        transformed_response["to"] = transformed_response["to"].get("hash")

    # 5. Return the optimized dictionary
    return transformed_response
```

### Progress Reporting

To ensure good observability and debuggability, all progress updates should be reported to the client and simultaneously logged as an `info` message. This provides immediate feedback for developers via logs, while also supporting clients that can render progress UIs.

Instead of calling `ctx.report_progress` directly, **always use the `report_and_log_progress` helper function** from `tools/common.py`.

**Implementation Pattern:**

```python
from blockscout_mcp_server.tools.common import report_and_log_progress

async def some_tool_with_progress(
    chain_id: Annotated[str, Field(description="The ID of the blockchain")],
    ctx: Context
):
    """A tool demonstrating correct progress reporting."""
    # Report start
    await report_and_log_progress(
        ctx, progress=0.0, total=2.0, message="Starting operation..."
    )

    # ... perform some work ...
    base_url = await get_blockscout_base_url(chain_id)

    # Report intermediate step
    await report_and_log_progress(
        ctx, progress=1.0, total=2.0, message="Resolved Blockscout URL. Fetching data..."
    )

    # ... perform the final step ...
    response_data = await make_blockscout_request(base_url, "/api/v2/some_endpoint")

    # Report completion
    await report_and_log_progress(
        ctx, progress=2.0, total=2.0, message="Successfully fetched data."
    )

    return response_data
```

This centralized helper ensures that every progress update is visible, regardless of the MCP client's capabilities.

### Performance Optimization

#### Concurrent API Calls

**When to Use:** When your tool needs data from multiple independent API sources (e.g., Blockscout + Metadata, block + transactions).

**Implementation Pattern:**

```python
import asyncio

# Execute multiple API calls concurrently
result1, result2 = await asyncio.gather(
    make_blockscout_request(base_url=base_url, api_path="/api/v2/addresses/{address}"),
    make_metadata_request(api_path="/api/v1/metadata", params={"addresses": address}),
    return_exceptions=True  # Critical: prevents one failure from breaking the entire operation
)

# Handle results with proper exception checking
if isinstance(result1, Exception):
    return f"Error fetching primary data: {result1}"

output_parts = ["Primary data:", json.dumps(result1)]

# Handle secondary data gracefully
if not isinstance(result2, Exception) and result2:
    output_parts.append("\nSecondary data:")
    output_parts.append(json.dumps(result2))

return "\n".join(output_parts)
```

**Key Points:**
- Always use `return_exceptions=True`